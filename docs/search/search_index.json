{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"context-async-sqlalchemy SOURCE CODE Provides a super convenient way to work with SQLAlchemy in asynchronous applications. It handles the lifecycle management of the engine, sessions, and transactions. The main goal is to provide quick and easy access to a session, without having to worry about opening or closing it when it\u2019s not necessary. Key features: Extremely easy to use Automatically manages the lifecycle of the engine, sessions, and transactions (autocommit / autorollback) Does not interfere with manually opening or closing sessions and transactions when needed Framework-agnostic - works with any web framework Not a wrapper around SQLAlchemy Convenient for testing Runtime host switching Supports multiple databases and multiple sessions per database Provides tools for running concurrent SQL queries Fully lazy initialization What does usage look like? from context_async_sqlalchemy import db_session from sqlalchemy import insert from database import connection # your configured connection to the database from models import ExampleTable # just some model for example async def some_func() -> None: # Created a session (no connection to the database yet) session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) # The second request will use the same connection and the same transaction await session.execute(stmt) # The commit and closing of the session will occur automatically How it works Here is a very simplified diagram of how everything works: Before executing your code, the middleware will prepare a container in which the sessions required by your code will be stored. The container is saved in contextvars Your code accesses the library to create new sessions and retrieve existing ones After your code, middleware will automatically commit or roll back open transactions. Closes open sessions and clears the context. The library also provides the ability to commit, rollback, and close at any time, without waiting for the end of the request, without any problems.","title":"context-async-sqlalchemy"},{"location":"#context-async-sqlalchemy","text":"SOURCE CODE Provides a super convenient way to work with SQLAlchemy in asynchronous applications. It handles the lifecycle management of the engine, sessions, and transactions. The main goal is to provide quick and easy access to a session, without having to worry about opening or closing it when it\u2019s not necessary. Key features: Extremely easy to use Automatically manages the lifecycle of the engine, sessions, and transactions (autocommit / autorollback) Does not interfere with manually opening or closing sessions and transactions when needed Framework-agnostic - works with any web framework Not a wrapper around SQLAlchemy Convenient for testing Runtime host switching Supports multiple databases and multiple sessions per database Provides tools for running concurrent SQL queries Fully lazy initialization","title":"context-async-sqlalchemy"},{"location":"#what-does-usage-look-like","text":"from context_async_sqlalchemy import db_session from sqlalchemy import insert from database import connection # your configured connection to the database from models import ExampleTable # just some model for example async def some_func() -> None: # Created a session (no connection to the database yet) session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) # The second request will use the same connection and the same transaction await session.execute(stmt) # The commit and closing of the session will occur automatically","title":"What does usage look like?"},{"location":"#how-it-works","text":"Here is a very simplified diagram of how everything works: Before executing your code, the middleware will prepare a container in which the sessions required by your code will be stored. The container is saved in contextvars Your code accesses the library to create new sessions and retrieve existing ones After your code, middleware will automatically commit or roll back open transactions. Closes open sessions and clears the context. The library also provides the ability to commit, rollback, and close at any time, without waiting for the end of the request, without any problems.","title":"How it works"},{"location":"concurrent_queries/","text":"Concurrent sql queries Concurrent query execution deserves special attention. In SQLAlchemy, you can\u2019t run multiple queries concurrently within the same session - you need to create a new one. The library provides two simple ways to execute queries concurrently: Run a function in a new context - run_in_new_ctx Create a new session that is completely independent of the current context - new_non_ctx_atomic_session or new_non_ctx_session import asyncio from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, new_non_ctx_atomic_session, new_non_ctx_session, run_in_new_ctx, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_multiple_sessions() -> None: \"\"\" In some situations, you need to have multiple sessions running simultaneously. For example, to run several queries concurrently. You can also use these same techniques to create new sessions whenever you need them. Not necessarily just because of the concurrent processing. \"\"\" await asyncio.gather( _insert(), # context session run_in_new_ctx(_insert), # new context and session with autocommit run_in_new_ctx( # new context and session with manual commit _insert_manual, \"example_multiple_sessions\", ), _insert_non_ctx(), # new non context session _insert_non_ctx_manual(), # new non context session ) async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_manual(text: str) -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=text) await session.execute(stmt) # You can manually commit the transaction if you want, but it is not # necessary await commit_db_session(connection) # You can manually close the session if you want, but it is not necessary await close_db_session(connection) async def _insert_non_ctx() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_atomic_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_non_ctx_manual() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) await session.commit()","title":"Concurrent SQL Queries"},{"location":"concurrent_queries/#concurrent-sql-queries","text":"Concurrent query execution deserves special attention. In SQLAlchemy, you can\u2019t run multiple queries concurrently within the same session - you need to create a new one. The library provides two simple ways to execute queries concurrently: Run a function in a new context - run_in_new_ctx Create a new session that is completely independent of the current context - new_non_ctx_atomic_session or new_non_ctx_session import asyncio from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, new_non_ctx_atomic_session, new_non_ctx_session, run_in_new_ctx, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_multiple_sessions() -> None: \"\"\" In some situations, you need to have multiple sessions running simultaneously. For example, to run several queries concurrently. You can also use these same techniques to create new sessions whenever you need them. Not necessarily just because of the concurrent processing. \"\"\" await asyncio.gather( _insert(), # context session run_in_new_ctx(_insert), # new context and session with autocommit run_in_new_ctx( # new context and session with manual commit _insert_manual, \"example_multiple_sessions\", ), _insert_non_ctx(), # new non context session _insert_non_ctx_manual(), # new non context session ) async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_manual(text: str) -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=text) await session.execute(stmt) # You can manually commit the transaction if you want, but it is not # necessary await commit_db_session(connection) # You can manually close the session if you want, but it is not necessary await close_db_session(connection) async def _insert_non_ctx() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_atomic_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_non_ctx_manual() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) await session.commit()","title":"Concurrent sql queries"},{"location":"examples/","text":"Usage examples You can see not only fragments of examples, but also web application examples . Basic usage from sqlalchemy import insert from context_async_sqlalchemy import db_session from ..database import connection from ..models import ExampleTable async def handler_with_db_session() -> None: \"\"\" An example of a typical handle that uses a context session to work with a database. Autocommit or autorollback occurs automatically at the end of a request (in middleware). \"\"\" # Created a session (no connection to the database yet) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # Commit will happen automatically Atomic from context_async_sqlalchemy import atomic_db_session, db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_atomic() -> None: \"\"\" Let's imagine you already have a function that works with a contextual session, and its use case calls autocommit at the end of the request. You want to reuse this function, but you need to commit immediately, rather than wait for the request to complete. \"\"\" # the transaction will be committed or rolled back automatically # using the context manager async with atomic_db_session(connection): await _insert_1() # This is a new transaction in the same connection await _insert_1() async def _insert_1() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_atomic\" ) await session.execute(stmt) Manually close the transaction and session from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_manual_close() -> None: \"\"\" An example of a handle that uses a session in context, but commits manually and even closes the session to release the connection. \"\"\" # new connect -> new transaction -> commit await _insert_1() # old connect -> new transaction -> commit -> close connect await _insert_2() # new connect -> new transaction await _insert_3() # same connect -> same transaction await _insert_3() # autocommit async def _insert_1() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt) # Here we closed the transaction await session.commit() # or await commit_db_session() async def _insert_2() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt) # Here we closed the transaction await commit_db_session(connection) # And here we closed the session = returned the connection to the pool # This is useful if, for example, at the beginning of the handle a # database query is needed, and then there is some other long-term work # and you don't want to keep the connection opened. await close_db_session(connection) async def _insert_3() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt) Multiple sessions and concurrent execution import asyncio from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, new_non_ctx_atomic_session, new_non_ctx_session, run_in_new_ctx, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_multiple_sessions() -> None: \"\"\" In some situations, you need to have multiple sessions running simultaneously. For example, to run several queries concurrently. You can also use these same techniques to create new sessions whenever you need them. Not necessarily just because of the concurrent processing. \"\"\" await asyncio.gather( _insert(), # context session run_in_new_ctx(_insert), # new context and session with autocommit run_in_new_ctx( # new context and session with manual commit _insert_manual, \"example_multiple_sessions\", ), _insert_non_ctx(), # new non context session _insert_non_ctx_manual(), # new non context session ) async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_manual(text: str) -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=text) await session.execute(stmt) # You can manually commit the transaction if you want, but it is not # necessary await commit_db_session(connection) # You can manually close the session if you want, but it is not necessary await close_db_session(connection) async def _insert_non_ctx() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_atomic_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_non_ctx_manual() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) await session.commit() Rollback from context_async_sqlalchemy import db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_exception() -> None: \"\"\" let's imagine that an exception occurred. \"\"\" session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") await session.execute(stmt) raise Exception(\"Some exception\") # transaction will be automatically rolled back from fastapi import HTTPException from context_async_sqlalchemy import db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_http_exception() -> None: \"\"\" let's imagine that an http exception occurred. \"\"\" session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") await session.execute(stmt) raise HTTPException(status_code=500) # transaction will be automatically rolled back by status code from context_async_sqlalchemy import db_session, rollback_db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_manual_rollback() -> None: \"\"\" An example of a handle that uses a rollback \"\"\" # it's convenient this way await _insert() await rollback_db_session(connection) # but it's possible this way too await _insert() session = await db_session(connection) await session.rollback() async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt)","title":"Usage Examples"},{"location":"examples/#usage-examples","text":"You can see not only fragments of examples, but also web application examples .","title":"Usage examples"},{"location":"examples/#basic-usage","text":"from sqlalchemy import insert from context_async_sqlalchemy import db_session from ..database import connection from ..models import ExampleTable async def handler_with_db_session() -> None: \"\"\" An example of a typical handle that uses a context session to work with a database. Autocommit or autorollback occurs automatically at the end of a request (in middleware). \"\"\" # Created a session (no connection to the database yet) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # Commit will happen automatically","title":"Basic usage"},{"location":"examples/#atomic","text":"from context_async_sqlalchemy import atomic_db_session, db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_atomic() -> None: \"\"\" Let's imagine you already have a function that works with a contextual session, and its use case calls autocommit at the end of the request. You want to reuse this function, but you need to commit immediately, rather than wait for the request to complete. \"\"\" # the transaction will be committed or rolled back automatically # using the context manager async with atomic_db_session(connection): await _insert_1() # This is a new transaction in the same connection await _insert_1() async def _insert_1() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_atomic\" ) await session.execute(stmt)","title":"Atomic"},{"location":"examples/#manually-close-the-transaction-and-session","text":"from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_manual_close() -> None: \"\"\" An example of a handle that uses a session in context, but commits manually and even closes the session to release the connection. \"\"\" # new connect -> new transaction -> commit await _insert_1() # old connect -> new transaction -> commit -> close connect await _insert_2() # new connect -> new transaction await _insert_3() # same connect -> same transaction await _insert_3() # autocommit async def _insert_1() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt) # Here we closed the transaction await session.commit() # or await commit_db_session() async def _insert_2() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt) # Here we closed the transaction await commit_db_session(connection) # And here we closed the session = returned the connection to the pool # This is useful if, for example, at the beginning of the handle a # database query is needed, and then there is some other long-term work # and you don't want to keep the connection opened. await close_db_session(connection) async def _insert_3() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt)","title":"Manually close the transaction and session"},{"location":"examples/#multiple-sessions-and-concurrent-execution","text":"import asyncio from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, new_non_ctx_atomic_session, new_non_ctx_session, run_in_new_ctx, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_multiple_sessions() -> None: \"\"\" In some situations, you need to have multiple sessions running simultaneously. For example, to run several queries concurrently. You can also use these same techniques to create new sessions whenever you need them. Not necessarily just because of the concurrent processing. \"\"\" await asyncio.gather( _insert(), # context session run_in_new_ctx(_insert), # new context and session with autocommit run_in_new_ctx( # new context and session with manual commit _insert_manual, \"example_multiple_sessions\", ), _insert_non_ctx(), # new non context session _insert_non_ctx_manual(), # new non context session ) async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_manual(text: str) -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=text) await session.execute(stmt) # You can manually commit the transaction if you want, but it is not # necessary await commit_db_session(connection) # You can manually close the session if you want, but it is not necessary await close_db_session(connection) async def _insert_non_ctx() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_atomic_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_non_ctx_manual() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) await session.commit()","title":"Multiple sessions and concurrent execution"},{"location":"examples/#rollback","text":"from context_async_sqlalchemy import db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_exception() -> None: \"\"\" let's imagine that an exception occurred. \"\"\" session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") await session.execute(stmt) raise Exception(\"Some exception\") # transaction will be automatically rolled back from fastapi import HTTPException from context_async_sqlalchemy import db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_http_exception() -> None: \"\"\" let's imagine that an http exception occurred. \"\"\" session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") await session.execute(stmt) raise HTTPException(status_code=500) # transaction will be automatically rolled back by status code from context_async_sqlalchemy import db_session, rollback_db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_manual_rollback() -> None: \"\"\" An example of a handle that uses a rollback \"\"\" # it's convenient this way await _insert() await rollback_db_session(connection) # but it's possible this way too await _insert() session = await db_session(connection) await session.rollback() async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt)","title":"Rollback"},{"location":"getting_started/","text":"Getting started Configure the connection to the database For example, for PostgreSQL - database.py: from sqlalchemy.ext.asyncio import ( async_sessionmaker, AsyncEngine, AsyncSession, create_async_engine, ) from context_async_sqlalchemy import DBConnect def create_engine(host: str) -> AsyncEngine: \"\"\" database connection parameters. \"\"\" # In production code, you will probably take these parameters from env pg_user = \"krylosov-aa\" pg_password = \"\" pg_port = 6432 pg_db = \"test\" return create_async_engine( f\"postgresql+asyncpg://\" f\"{pg_user}:{pg_password}\" f\"@{host}:{pg_port}\" f\"/{pg_db}\", future=True, pool_pre_ping=True, ) def create_session_maker( engine: AsyncEngine, ) -> async_sessionmaker[AsyncSession]: \"\"\"session parameters\"\"\" return async_sessionmaker( engine, class_=AsyncSession, expire_on_commit=False ) connection = DBConnect( host=\"127.0.0.1\", engine_creator=create_engine, session_maker_creator=create_session_maker, ) Manage Database connection lifecycle Close resources at the end of your application's lifecycle. Example for FastAPI: from contextlib import asynccontextmanager from typing import Any, AsyncGenerator from fastapi import FastAPI from database import connection @asynccontextmanager async def lifespan(app: FastAPI) -> AsyncGenerator[None, Any]: \"\"\"Database connection lifecycle management\"\"\" yield await connection.close() # Close the engine if it was open Setup middleware Middleware handles the most important and complex part - managing context and sessions. You can use the ready-made middleware components: FastAPI from context_async_sqlalchemy.fastapi_utils import ( add_fastapi_http_db_session_middleware, ) app = FastAPI(...) add_fastapi_http_db_session_middleware(app) Starlette from context_async_sqlalchemy.starlette_utils import ( add_starlette_http_db_session_middleware, ) app = Starlette(...) add_starlette_http_db_session_middleware(app) Write own If there\u2019s no ready-made solution that fits your needs - don\u2019t worry! You can check out how it works and implement your own. Use it from context_async_sqlalchemy import db_session from sqlalchemy import insert from database import connection # your configured connection to the database from models import ExampleTable # just some model for example async def some_func() -> None: # Created a session (no connection to the database yet) session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) # The second request will use the same connection and the same transaction await session.execute(stmt) # The commit and closing of the session will occur automatically Examples The repository includes an example integration with FastAPI, demonstrating various workflows: FastAPI example It also contains two types of test setups that you can use in your own projects. All library tests are included within the examples - because we aim to test the functionality not in isolation, but in the context of a real asynchronous web application. FastAPI tests example","title":"Getting Started"},{"location":"getting_started/#getting-started","text":"","title":"Getting started"},{"location":"getting_started/#configure-the-connection-to-the-database","text":"For example, for PostgreSQL - database.py: from sqlalchemy.ext.asyncio import ( async_sessionmaker, AsyncEngine, AsyncSession, create_async_engine, ) from context_async_sqlalchemy import DBConnect def create_engine(host: str) -> AsyncEngine: \"\"\" database connection parameters. \"\"\" # In production code, you will probably take these parameters from env pg_user = \"krylosov-aa\" pg_password = \"\" pg_port = 6432 pg_db = \"test\" return create_async_engine( f\"postgresql+asyncpg://\" f\"{pg_user}:{pg_password}\" f\"@{host}:{pg_port}\" f\"/{pg_db}\", future=True, pool_pre_ping=True, ) def create_session_maker( engine: AsyncEngine, ) -> async_sessionmaker[AsyncSession]: \"\"\"session parameters\"\"\" return async_sessionmaker( engine, class_=AsyncSession, expire_on_commit=False ) connection = DBConnect( host=\"127.0.0.1\", engine_creator=create_engine, session_maker_creator=create_session_maker, )","title":"Configure the connection to the database"},{"location":"getting_started/#manage-database-connection-lifecycle","text":"Close resources at the end of your application's lifecycle. Example for FastAPI: from contextlib import asynccontextmanager from typing import Any, AsyncGenerator from fastapi import FastAPI from database import connection @asynccontextmanager async def lifespan(app: FastAPI) -> AsyncGenerator[None, Any]: \"\"\"Database connection lifecycle management\"\"\" yield await connection.close() # Close the engine if it was open","title":"Manage Database connection lifecycle"},{"location":"getting_started/#setup-middleware","text":"Middleware handles the most important and complex part - managing context and sessions. You can use the ready-made middleware components:","title":"Setup middleware"},{"location":"getting_started/#fastapi","text":"from context_async_sqlalchemy.fastapi_utils import ( add_fastapi_http_db_session_middleware, ) app = FastAPI(...) add_fastapi_http_db_session_middleware(app)","title":"FastAPI"},{"location":"getting_started/#starlette","text":"from context_async_sqlalchemy.starlette_utils import ( add_starlette_http_db_session_middleware, ) app = Starlette(...) add_starlette_http_db_session_middleware(app)","title":"Starlette"},{"location":"getting_started/#write-own","text":"If there\u2019s no ready-made solution that fits your needs - don\u2019t worry! You can check out how it works and implement your own.","title":"Write own"},{"location":"getting_started/#use-it","text":"from context_async_sqlalchemy import db_session from sqlalchemy import insert from database import connection # your configured connection to the database from models import ExampleTable # just some model for example async def some_func() -> None: # Created a session (no connection to the database yet) session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) # The second request will use the same connection and the same transaction await session.execute(stmt) # The commit and closing of the session will occur automatically","title":"Use it"},{"location":"getting_started/#examples","text":"The repository includes an example integration with FastAPI, demonstrating various workflows: FastAPI example It also contains two types of test setups that you can use in your own projects. All library tests are included within the examples - because we aim to test the functionality not in isolation, but in the context of a real asynchronous web application. FastAPI tests example","title":"Examples"},{"location":"how_middleware_works/","text":"How middleware works Most of the work - and the \u201cmagic\u201d - happens inside the middleware. The library aims to provide ready-made solutions so that you don\u2019t have to worry about these details - but they\u2019re not always available. So, let\u2019s take a look at how Starlette middleware works. You can use this example as a reference to implement your own. from starlette.middleware.base import ( # type: ignore[attr-defined] Request, Response, RequestResponseEndpoint, BaseHTTPMiddleware, ) from context_async_sqlalchemy import ( init_db_session_ctx, is_context_initiated, reset_db_session_ctx, auto_commit_by_status_code, rollback_all_sessions, ) async def starlette_http_db_session_middleware( request: Request, call_next: RequestResponseEndpoint ) -> Response: \"\"\" Database session lifecycle management. The session itself is created on demand in db_session(). Transaction auto-commit is implemented if there is no exception and the response status is < 400. Otherwise, a rollback is performed. But you can commit or rollback manually in the handler. \"\"\" # Tests have different session management rules # so if the context variable is already set, we do nothing if is_context_initiated(): return await call_next(request) # We set the context here, meaning all child coroutines will receive the # same context. And even if a child coroutine requests the # session first, the container itself is shared, and this coroutine will # add the session to container = shared context. token = init_db_session_ctx() try: response = await call_next(request) # using the status code, we decide to commit or rollback all sessions await auto_commit_by_status_code(response.status_code) return response except Exception: # If an exception occurs, we roll all sessions back await rollback_all_sessions() raise finally: # Close all sessions and clear the context await reset_db_session_ctx(token)","title":"How middleware works"},{"location":"how_middleware_works/#how-middleware-works","text":"Most of the work - and the \u201cmagic\u201d - happens inside the middleware. The library aims to provide ready-made solutions so that you don\u2019t have to worry about these details - but they\u2019re not always available. So, let\u2019s take a look at how Starlette middleware works. You can use this example as a reference to implement your own. from starlette.middleware.base import ( # type: ignore[attr-defined] Request, Response, RequestResponseEndpoint, BaseHTTPMiddleware, ) from context_async_sqlalchemy import ( init_db_session_ctx, is_context_initiated, reset_db_session_ctx, auto_commit_by_status_code, rollback_all_sessions, ) async def starlette_http_db_session_middleware( request: Request, call_next: RequestResponseEndpoint ) -> Response: \"\"\" Database session lifecycle management. The session itself is created on demand in db_session(). Transaction auto-commit is implemented if there is no exception and the response status is < 400. Otherwise, a rollback is performed. But you can commit or rollback manually in the handler. \"\"\" # Tests have different session management rules # so if the context variable is already set, we do nothing if is_context_initiated(): return await call_next(request) # We set the context here, meaning all child coroutines will receive the # same context. And even if a child coroutine requests the # session first, the container itself is shared, and this coroutine will # add the session to container = shared context. token = init_db_session_ctx() try: response = await call_next(request) # using the status code, we decide to commit or rollback all sessions await auto_commit_by_status_code(response.status_code) return response except Exception: # If an exception occurs, we roll all sessions back await rollback_all_sessions() raise finally: # Close all sessions and clear the context await reset_db_session_ctx(token)","title":"How middleware works"},{"location":"master_replica/","text":"Master/Replica or several databases at the same time This is why db_session and other functions accept a DBConnect instance as input. This approach allows you to work with multiple hosts simultaneously - for example, with both a master and a replica. DBConnect can also accept factory functions instead of ready-made objects, making it easy to switch hosts when needed. For example, libpq can detect the master and replica when creating an engine, but it only does this once - at creation time. The before_create_session_handler hook allows you to change the host at runtime if the master or replica changes. You\u2019ll need third-party functionality to determine which host is the master or the replica. Hopefully, I\u2019ll be able to provide a ready-made solution for this soon. . The engine is not created immediately when DBConnect is initialized - it is created only on the first request. The library uses lazy initialization in many places. from context_async_sqlalchemy import DBConnect from master_replica_helper import get_master, get_replica async def renew_master_connect(connect: DBConnect) -> None: \"\"\"Updates the host if the master has changed\"\"\" master_host = await get_master() if master_host != connect.host: await connect.change_host(master_host) master = DBConnect( ..., before_create_session_handler=renew_master_connect, ) async def renew_replica_connect(connect: DBConnect) -> None: \"\"\"Updates the host if the replica has changed\"\"\" replica_host = await get_replica() if replica_host != connect.host: await connect.change_host(replica_host) replica = DBConnect( ..., before_create_session_handler=renew_replica_connect, )","title":"Master/Replica or several databases at the same time"},{"location":"master_replica/#masterreplica-or-several-databases-at-the-same-time","text":"This is why db_session and other functions accept a DBConnect instance as input. This approach allows you to work with multiple hosts simultaneously - for example, with both a master and a replica. DBConnect can also accept factory functions instead of ready-made objects, making it easy to switch hosts when needed. For example, libpq can detect the master and replica when creating an engine, but it only does this once - at creation time. The before_create_session_handler hook allows you to change the host at runtime if the master or replica changes. You\u2019ll need third-party functionality to determine which host is the master or the replica. Hopefully, I\u2019ll be able to provide a ready-made solution for this soon. . The engine is not created immediately when DBConnect is initialized - it is created only on the first request. The library uses lazy initialization in many places. from context_async_sqlalchemy import DBConnect from master_replica_helper import get_master, get_replica async def renew_master_connect(connect: DBConnect) -> None: \"\"\"Updates the host if the master has changed\"\"\" master_host = await get_master() if master_host != connect.host: await connect.change_host(master_host) master = DBConnect( ..., before_create_session_handler=renew_master_connect, ) async def renew_replica_connect(connect: DBConnect) -> None: \"\"\"Updates the host if the replica has changed\"\"\" replica_host = await get_replica() if replica_host != connect.host: await connect.change_host(replica_host) replica = DBConnect( ..., before_create_session_handler=renew_replica_connect, )","title":"Master/Replica or several databases at the same time"},{"location":"problem/","text":"The Problem It Solves SQLAlchemy uses an engine that manages the connection pool. The engine must remain active for as long as the application is running, so it can quickly provide ready-to-use connections whenever the application needs them. In the application, we work with sessions. A session obtains a single connection from the pool and should have a short lifespan - usually lasting only for the duration of a single request, or even less. Let's see what existing solutions are available to manage sessions: Manual solution This is how the code ends up being duplicated, and two connections and two transactions are used - even though in many cases only one connection and one transaction are actually needed. @app.post(\"/users/\") async def create_user(name): await insert_user(name) await insert_user_profile(name) async def insert_user(name): async with get_async_session() as session: async with session.begin(): await session.execute(stmt) async def insert_user_profile(name): async with get_async_session() as session: async with session.begin(): await session.execute(stmt) You can move the duplicated code to a higher level, which will result in using a single connection and a single transaction. @app.post(\"/users/\") async def create_user(name:): async with get_async_session() as session: async with session.begin(): await insert_user(name, session) await insert_user_profile(name, session) async def insert_user(name, session): await session.execute(stmt) async def insert_user_profile(name, session): await session.execute(stmt) But if you look at it more broadly, the code duplication doesn\u2019t actually go away - you still have to do this in every handler. @app.post(\"/dogs/\") async def create_dog(name): async with get_async_session() as session: async with session.begin(): ... @app.post(\"/cats\") async def create_cat(name): async with get_async_session() as session: async with session.begin(): ... You also have to set everything up yourself. No ready-made integration solutions are used - which means freedom on one hand, but a lot of code on the other. Dependency You can use a dependency. For example, in FastAPI, it looks like this: async def get_atomic_session(): async with session_maker() as session: async with session.begin(): yield session @app.post(\"/dogs/\") async def create_dog(name, session=Depends(get_atomic_session)): ... @app.post(\"/cats/\") async def create_cat(name, session=Depends(get_atomic_session)): ... There are two problems here: You can\u2019t close the session or transaction prematurely, because the dependency is responsible for that. The session has to be passed all the way down the stack to the place where it\u2019s actually needed. By the way, there\u2019s no ready-made solution for integrating with the framework - you have to implement the dependency yourself. Wrappers over sqlalachemy There are various wrappers that often provide more convenient integration. Litestar, for example, has the same advantages and disadvantages as using dependencies: config = SQLAlchemyAsyncConfig( connection_string=URL ) sqlalchemy_plugin = SQLAlchemyInitPlugin(config) class UserRepository(SQLAlchemyAsyncRepository[User]): model_type = User @post(\"/users\") async def create_user(data: User, repo: UserRepository): await repo.add(data) # <- insert into User Here\u2019s an example using Ormar: class BaseMeta(ormar.ModelMeta): ... class User(ormar.Model): ... @app.post(\"/users/\") async def create_user(name): await User.objects.create(name=name) The main problem with wrappers is that they require developers to learn something new. They introduce their own syntax - so even if a developer is familiar with SQLAlchemy, it doesn\u2019t mean they\u2019ll understand the wrapper. Wrappers are also often designed for convenience when working with simple CRUD operations, but writing complex SQL queries with them can be very challenging. Solution And this library solves all of these issues: Easy integration with web frameworks Automatic management of engine, session, and transaction lifecycles Ability to manually close a session at any time, without waiting for the end of process Access to a session from the context only where it\u2019s actually needed","title":"The Problem It Solves"},{"location":"problem/#the-problem-it-solves","text":"SQLAlchemy uses an engine that manages the connection pool. The engine must remain active for as long as the application is running, so it can quickly provide ready-to-use connections whenever the application needs them. In the application, we work with sessions. A session obtains a single connection from the pool and should have a short lifespan - usually lasting only for the duration of a single request, or even less. Let's see what existing solutions are available to manage sessions:","title":"The Problem It Solves"},{"location":"problem/#manual-solution","text":"This is how the code ends up being duplicated, and two connections and two transactions are used - even though in many cases only one connection and one transaction are actually needed. @app.post(\"/users/\") async def create_user(name): await insert_user(name) await insert_user_profile(name) async def insert_user(name): async with get_async_session() as session: async with session.begin(): await session.execute(stmt) async def insert_user_profile(name): async with get_async_session() as session: async with session.begin(): await session.execute(stmt) You can move the duplicated code to a higher level, which will result in using a single connection and a single transaction. @app.post(\"/users/\") async def create_user(name:): async with get_async_session() as session: async with session.begin(): await insert_user(name, session) await insert_user_profile(name, session) async def insert_user(name, session): await session.execute(stmt) async def insert_user_profile(name, session): await session.execute(stmt) But if you look at it more broadly, the code duplication doesn\u2019t actually go away - you still have to do this in every handler. @app.post(\"/dogs/\") async def create_dog(name): async with get_async_session() as session: async with session.begin(): ... @app.post(\"/cats\") async def create_cat(name): async with get_async_session() as session: async with session.begin(): ... You also have to set everything up yourself. No ready-made integration solutions are used - which means freedom on one hand, but a lot of code on the other.","title":"Manual solution"},{"location":"problem/#dependency","text":"You can use a dependency. For example, in FastAPI, it looks like this: async def get_atomic_session(): async with session_maker() as session: async with session.begin(): yield session @app.post(\"/dogs/\") async def create_dog(name, session=Depends(get_atomic_session)): ... @app.post(\"/cats/\") async def create_cat(name, session=Depends(get_atomic_session)): ... There are two problems here: You can\u2019t close the session or transaction prematurely, because the dependency is responsible for that. The session has to be passed all the way down the stack to the place where it\u2019s actually needed. By the way, there\u2019s no ready-made solution for integrating with the framework - you have to implement the dependency yourself.","title":"Dependency"},{"location":"problem/#wrappers-over-sqlalachemy","text":"There are various wrappers that often provide more convenient integration. Litestar, for example, has the same advantages and disadvantages as using dependencies: config = SQLAlchemyAsyncConfig( connection_string=URL ) sqlalchemy_plugin = SQLAlchemyInitPlugin(config) class UserRepository(SQLAlchemyAsyncRepository[User]): model_type = User @post(\"/users\") async def create_user(data: User, repo: UserRepository): await repo.add(data) # <- insert into User Here\u2019s an example using Ormar: class BaseMeta(ormar.ModelMeta): ... class User(ormar.Model): ... @app.post(\"/users/\") async def create_user(name): await User.objects.create(name=name) The main problem with wrappers is that they require developers to learn something new. They introduce their own syntax - so even if a developer is familiar with SQLAlchemy, it doesn\u2019t mean they\u2019ll understand the wrapper. Wrappers are also often designed for convenience when working with simple CRUD operations, but writing complex SQL queries with them can be very challenging.","title":"Wrappers over sqlalachemy"},{"location":"problem/#solution","text":"And this library solves all of these issues: Easy integration with web frameworks Automatic management of engine, session, and transaction lifecycles Ability to manually close a session at any time, without waiting for the end of process Access to a session from the context only where it\u2019s actually needed","title":"Solution"},{"location":"testing/","text":"Testing When testing with a real database, one important problem needs to be solved - ensuring data isolation between tests. There are basically two approaches: Separate sessions. The test has its own session that it uses to prepare data and verify results after execution. The application also has its own session. Data isolation is achieved by clearing all tables at the end of each test (and once before running all tests). Shared session and transaction. The test and the application share the same session and transaction. Data isolation is achieved by rolling back the transaction at the end of the test. Personally, I prefer the first option, because it is a more \"honest\" way to test the application. We can verify how it handles sessions and transactions on its own. It\u2019s also convenient to inspect the database state when a test is paused. Sometimes, there are complex session management scenarios (for example, concurrent query execution) where other types of testing are either impossible or very difficult. The main disadvantage of this approach is the slower execution speed. Since we clear all tables after each test, this process takes additional time. This is where the second approach comes in - its main advantage is speed, as rolling back a transaction is very fast. In my projects, I use both approaches at the same time: For most tests with simple or common logic, I use a shared transaction for the test and the application For more complex cases, or ones that cannot be tested this way, I use separate transactions. This combination allows for both good performance and convenient testing. The library provides several utilities that can be used in tests - for example, in fixtures. They help create tests that share a common transaction between the test and the application, so data isolation between tests is achieved through fast transaction rollback. You can see these capabilities in the examples: Here are tests with a common transaction between the application and the tests. And here's an example with different transactions. Create session with autorollback rollback_session creates a session that always rolls back automatically. from context_async_sqlalchemy.test_utils import rollback_session @pytest_asyncio.fixture async def db_session_test() -> AsyncGenerator[AsyncSession]: \"\"\"The session that is used inside the test\"\"\" async with rollback_session(connection) as session: yield session Override context set_test_context creates a new context put_savepoint_session_in_ctx puts into context a session that uses the same connection as db_session_test , but if you commit in this session, then the transaction will not be committed, but save point will be released from context_async_sqlalchemy.test_utils import ( put_savepoint_session_in_ctx, set_test_context, ) @pytest_asyncio.fixture(autouse=True) async def db_session_override( db_session_test: AsyncSession, ) -> AsyncGenerator[None]: \"\"\" The key thing about these tests is that we override the context in advance. The middleware has a special check that won't initialize the context if it already exists. \"\"\" async with set_test_context(): async with put_savepoint_session_in_ctx(connection, db_session_test): yield","title":"Testing"},{"location":"testing/#testing","text":"When testing with a real database, one important problem needs to be solved - ensuring data isolation between tests. There are basically two approaches: Separate sessions. The test has its own session that it uses to prepare data and verify results after execution. The application also has its own session. Data isolation is achieved by clearing all tables at the end of each test (and once before running all tests). Shared session and transaction. The test and the application share the same session and transaction. Data isolation is achieved by rolling back the transaction at the end of the test. Personally, I prefer the first option, because it is a more \"honest\" way to test the application. We can verify how it handles sessions and transactions on its own. It\u2019s also convenient to inspect the database state when a test is paused. Sometimes, there are complex session management scenarios (for example, concurrent query execution) where other types of testing are either impossible or very difficult. The main disadvantage of this approach is the slower execution speed. Since we clear all tables after each test, this process takes additional time. This is where the second approach comes in - its main advantage is speed, as rolling back a transaction is very fast. In my projects, I use both approaches at the same time: For most tests with simple or common logic, I use a shared transaction for the test and the application For more complex cases, or ones that cannot be tested this way, I use separate transactions. This combination allows for both good performance and convenient testing. The library provides several utilities that can be used in tests - for example, in fixtures. They help create tests that share a common transaction between the test and the application, so data isolation between tests is achieved through fast transaction rollback. You can see these capabilities in the examples: Here are tests with a common transaction between the application and the tests. And here's an example with different transactions.","title":"Testing"},{"location":"testing/#create-session-with-autorollback","text":"rollback_session creates a session that always rolls back automatically. from context_async_sqlalchemy.test_utils import rollback_session @pytest_asyncio.fixture async def db_session_test() -> AsyncGenerator[AsyncSession]: \"\"\"The session that is used inside the test\"\"\" async with rollback_session(connection) as session: yield session","title":"Create session with autorollback"},{"location":"testing/#override-context","text":"set_test_context creates a new context put_savepoint_session_in_ctx puts into context a session that uses the same connection as db_session_test , but if you commit in this session, then the transaction will not be committed, but save point will be released from context_async_sqlalchemy.test_utils import ( put_savepoint_session_in_ctx, set_test_context, ) @pytest_asyncio.fixture(autouse=True) async def db_session_override( db_session_test: AsyncSession, ) -> AsyncGenerator[None]: \"\"\" The key thing about these tests is that we override the context in advance. The middleware has a special check that won't initialize the context if it already exists. \"\"\" async with set_test_context(): async with put_savepoint_session_in_ctx(connection, db_session_test): yield","title":"Override context"}]}