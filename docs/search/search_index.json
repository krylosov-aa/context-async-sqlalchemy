{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"context-async-sqlalchemy SOURCE CODE Provides a super convenient way to work with sqlalchemy in asynchronous applications. It takes care of the issues of managing the lifecycle of engine, session, and transactions without being a wrapper. The main task is to get quick and easy access to the session and not worry about when to open and when to close it. The key features are: Super easy to use Automatically manages the lifecycle of engine, session, and transaction (autocommit/autorollback) It doesn't interfere with manually opening and closing sessions and transactions when needed. Does not depend on the web framework It is not a wrapper over sqlalchemy It is convenient to test Host switching in runtime It can manage multiple databases and multiple sessions to a single database Provides tools for concurrent sql queries What does usage look like? from context_async_sqlalchemy import db_session from sqlalchemy import insert from database import connection # your configured connection to the database from models import ExampleTable # just some model for example async def some_func() -> None: # Created a session (no connection to the database yet) session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) # The second request will use the same connection and the same transaction await session.execute(stmt) # The commit and closing of the session will occur automatically How it works Here is a very simplified diagram of how everything works: Before executing your code, the middleware will prepare a container in which the sessions required by your code will be stored. The container is saved in contextvars Your code accesses the library to create new sessions and retrieve existing ones After your code, middleware will automatically commit or roll back open transactions. Closes open sessions and clears the context. The library also provides the ability to commit, rollback, and close at any time, without waiting for the end of the request, without any problems.","title":"context-async-sqlalchemy"},{"location":"#context-async-sqlalchemy","text":"SOURCE CODE Provides a super convenient way to work with sqlalchemy in asynchronous applications. It takes care of the issues of managing the lifecycle of engine, session, and transactions without being a wrapper. The main task is to get quick and easy access to the session and not worry about when to open and when to close it. The key features are: Super easy to use Automatically manages the lifecycle of engine, session, and transaction (autocommit/autorollback) It doesn't interfere with manually opening and closing sessions and transactions when needed. Does not depend on the web framework It is not a wrapper over sqlalchemy It is convenient to test Host switching in runtime It can manage multiple databases and multiple sessions to a single database Provides tools for concurrent sql queries","title":"context-async-sqlalchemy"},{"location":"#what-does-usage-look-like","text":"from context_async_sqlalchemy import db_session from sqlalchemy import insert from database import connection # your configured connection to the database from models import ExampleTable # just some model for example async def some_func() -> None: # Created a session (no connection to the database yet) session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) # The second request will use the same connection and the same transaction await session.execute(stmt) # The commit and closing of the session will occur automatically","title":"What does usage look like?"},{"location":"#how-it-works","text":"Here is a very simplified diagram of how everything works: Before executing your code, the middleware will prepare a container in which the sessions required by your code will be stored. The container is saved in contextvars Your code accesses the library to create new sessions and retrieve existing ones After your code, middleware will automatically commit or roll back open transactions. Closes open sessions and clears the context. The library also provides the ability to commit, rollback, and close at any time, without waiting for the end of the request, without any problems.","title":"How it works"},{"location":"concurrent_queries/","text":"Concurrent sql queries Concurrent query execution deserves special attention. In sqlalchemy, you cannot concurrently run multiple queries within the same session. You need to create a new session. The library provides 2 ways to execute queries concurrently very easily: calling a function with a new context - run_in_new_ctx get a new session that doesn't fit into the context at all - new_non_ctx_atomic_session or new_non_ctx_session import asyncio from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, new_non_ctx_atomic_session, new_non_ctx_session, run_in_new_ctx, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_multiple_sessions() -> None: \"\"\" In some situations, you need to have multiple sessions running simultaneously. For example, to run several queries concurrently. You can also use these same techniques to create new sessions whenever you need them. Not necessarily just because of the concurrent processing. \"\"\" await asyncio.gather( _insert(), # context session run_in_new_ctx(_insert), # new context and session with autocommit run_in_new_ctx( # new context and session with manual commit _insert_manual, \"example_multiple_sessions\", ), _insert_non_ctx(), # new non context session _insert_non_ctx_manual(), # new non context session ) async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_manual(text: str) -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=text) await session.execute(stmt) # You can manually commit the transaction if you want, but it is not # necessary await commit_db_session(connection) # You can manually close the session if you want, but it is not necessary await close_db_session(connection) async def _insert_non_ctx() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_atomic_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_non_ctx_manual() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) await session.commit()","title":"Concurrent sql queries"},{"location":"concurrent_queries/#concurrent-sql-queries","text":"Concurrent query execution deserves special attention. In sqlalchemy, you cannot concurrently run multiple queries within the same session. You need to create a new session. The library provides 2 ways to execute queries concurrently very easily: calling a function with a new context - run_in_new_ctx get a new session that doesn't fit into the context at all - new_non_ctx_atomic_session or new_non_ctx_session import asyncio from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, new_non_ctx_atomic_session, new_non_ctx_session, run_in_new_ctx, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_multiple_sessions() -> None: \"\"\" In some situations, you need to have multiple sessions running simultaneously. For example, to run several queries concurrently. You can also use these same techniques to create new sessions whenever you need them. Not necessarily just because of the concurrent processing. \"\"\" await asyncio.gather( _insert(), # context session run_in_new_ctx(_insert), # new context and session with autocommit run_in_new_ctx( # new context and session with manual commit _insert_manual, \"example_multiple_sessions\", ), _insert_non_ctx(), # new non context session _insert_non_ctx_manual(), # new non context session ) async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_manual(text: str) -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=text) await session.execute(stmt) # You can manually commit the transaction if you want, but it is not # necessary await commit_db_session(connection) # You can manually close the session if you want, but it is not necessary await close_db_session(connection) async def _insert_non_ctx() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_atomic_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_non_ctx_manual() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) await session.commit()","title":"Concurrent sql queries"},{"location":"examples/","text":"Usage examples You can see not only fragments of examples, but also web application examples . Basic usage from sqlalchemy import insert from context_async_sqlalchemy import db_session from ..database import connection from ..models import ExampleTable async def handler_with_db_session() -> None: \"\"\" An example of a typical handle that uses a context session to work with a database. Autocommit or autorollback occurs automatically at the end of a request (in middleware). \"\"\" # Created a session (no connection to the database yet) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # Commit will happen automatically Atomic from context_async_sqlalchemy import atomic_db_session, db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_atomic() -> None: \"\"\" Let's imagine you already have a function that works with a contextual session, and its use case calls autocommit at the end of the request. You want to reuse this function, but you need to commit immediately, rather than wait for the request to complete. \"\"\" # the transaction will be committed or rolled back automatically # using the context manager async with atomic_db_session(connection): await _insert_1() # This is a new transaction in the same connection await _insert_1() async def _insert_1() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_atomic\" ) await session.execute(stmt) Manually close the transaction and session from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_manual_close() -> None: \"\"\" An example of a handle that uses a session in context, but commits manually and even closes the session to release the connection. \"\"\" # new connect -> new transaction -> commit await _insert_1() # old connect -> new transaction -> commit -> close connect await _insert_2() # new connect -> new transaction await _insert_3() # same connect -> same transaction await _insert_3() # autocommit async def _insert_1() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt) # Here we closed the transaction await session.commit() # or await commit_db_session() async def _insert_2() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt) # Here we closed the transaction await commit_db_session(connection) # And here we closed the session = returned the connection to the pool # This is useful if, for example, at the beginning of the handle a # database query is needed, and then there is some other long-term work # and you don't want to keep the connection opened. await close_db_session(connection) async def _insert_3() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt) Multiple sessions and concurrent execution import asyncio from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, new_non_ctx_atomic_session, new_non_ctx_session, run_in_new_ctx, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_multiple_sessions() -> None: \"\"\" In some situations, you need to have multiple sessions running simultaneously. For example, to run several queries concurrently. You can also use these same techniques to create new sessions whenever you need them. Not necessarily just because of the concurrent processing. \"\"\" await asyncio.gather( _insert(), # context session run_in_new_ctx(_insert), # new context and session with autocommit run_in_new_ctx( # new context and session with manual commit _insert_manual, \"example_multiple_sessions\", ), _insert_non_ctx(), # new non context session _insert_non_ctx_manual(), # new non context session ) async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_manual(text: str) -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=text) await session.execute(stmt) # You can manually commit the transaction if you want, but it is not # necessary await commit_db_session(connection) # You can manually close the session if you want, but it is not necessary await close_db_session(connection) async def _insert_non_ctx() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_atomic_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_non_ctx_manual() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) await session.commit() Rollback from context_async_sqlalchemy import db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_exception() -> None: \"\"\" let's imagine that an exception occurred. \"\"\" session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") await session.execute(stmt) raise Exception(\"Some exception\") # transaction will be automatically rolled back from fastapi import HTTPException from context_async_sqlalchemy import db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_http_exception() -> None: \"\"\" let's imagine that an http exception occurred. \"\"\" session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") await session.execute(stmt) raise HTTPException(status_code=500) # transaction will be automatically rolled back by status code from context_async_sqlalchemy import db_session, rollback_db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_manual_rollback() -> None: \"\"\" An example of a handle that uses a rollback \"\"\" # it's convenient this way await _insert() await rollback_db_session(connection) # but it's possible this way too await _insert() session = await db_session(connection) await session.rollback() async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt)","title":"Usage examples"},{"location":"examples/#usage-examples","text":"You can see not only fragments of examples, but also web application examples .","title":"Usage examples"},{"location":"examples/#basic-usage","text":"from sqlalchemy import insert from context_async_sqlalchemy import db_session from ..database import connection from ..models import ExampleTable async def handler_with_db_session() -> None: \"\"\" An example of a typical handle that uses a context session to work with a database. Autocommit or autorollback occurs automatically at the end of a request (in middleware). \"\"\" # Created a session (no connection to the database yet) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # Commit will happen automatically","title":"Basic usage"},{"location":"examples/#atomic","text":"from context_async_sqlalchemy import atomic_db_session, db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_atomic() -> None: \"\"\" Let's imagine you already have a function that works with a contextual session, and its use case calls autocommit at the end of the request. You want to reuse this function, but you need to commit immediately, rather than wait for the request to complete. \"\"\" # the transaction will be committed or rolled back automatically # using the context manager async with atomic_db_session(connection): await _insert_1() # This is a new transaction in the same connection await _insert_1() async def _insert_1() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_atomic\" ) await session.execute(stmt)","title":"Atomic"},{"location":"examples/#manually-close-the-transaction-and-session","text":"from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_manual_close() -> None: \"\"\" An example of a handle that uses a session in context, but commits manually and even closes the session to release the connection. \"\"\" # new connect -> new transaction -> commit await _insert_1() # old connect -> new transaction -> commit -> close connect await _insert_2() # new connect -> new transaction await _insert_3() # same connect -> same transaction await _insert_3() # autocommit async def _insert_1() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt) # Here we closed the transaction await session.commit() # or await commit_db_session() async def _insert_2() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt) # Here we closed the transaction await commit_db_session(connection) # And here we closed the session = returned the connection to the pool # This is useful if, for example, at the beginning of the handle a # database query is needed, and then there is some other long-term work # and you don't want to keep the connection opened. await close_db_session(connection) async def _insert_3() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt)","title":"Manually close the transaction and session"},{"location":"examples/#multiple-sessions-and-concurrent-execution","text":"import asyncio from context_async_sqlalchemy import ( close_db_session, commit_db_session, db_session, new_non_ctx_atomic_session, new_non_ctx_session, run_in_new_ctx, ) from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_multiple_sessions() -> None: \"\"\" In some situations, you need to have multiple sessions running simultaneously. For example, to run several queries concurrently. You can also use these same techniques to create new sessions whenever you need them. Not necessarily just because of the concurrent processing. \"\"\" await asyncio.gather( _insert(), # context session run_in_new_ctx(_insert), # new context and session with autocommit run_in_new_ctx( # new context and session with manual commit _insert_manual, \"example_multiple_sessions\", ), _insert_non_ctx(), # new non context session _insert_non_ctx_manual(), # new non context session ) async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_manual(text: str) -> None: session = await db_session(connection) stmt = insert(ExampleTable).values(text=text) await session.execute(stmt) # You can manually commit the transaction if you want, but it is not # necessary await commit_db_session(connection) # You can manually close the session if you want, but it is not necessary await close_db_session(connection) async def _insert_non_ctx() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_atomic_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) async def _insert_non_ctx_manual() -> None: \"\"\" You don't have to use the context to work with sessions at all \"\"\" async with new_non_ctx_session(connection) as session: stmt = insert(ExampleTable).values(text=\"example_multiple_sessions\") await session.execute(stmt) await session.commit()","title":"Multiple sessions and concurrent execution"},{"location":"examples/#rollback","text":"from context_async_sqlalchemy import db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_exception() -> None: \"\"\" let's imagine that an exception occurred. \"\"\" session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") await session.execute(stmt) raise Exception(\"Some exception\") # transaction will be automatically rolled back from fastapi import HTTPException from context_async_sqlalchemy import db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_http_exception() -> None: \"\"\" let's imagine that an http exception occurred. \"\"\" session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") await session.execute(stmt) raise HTTPException(status_code=500) # transaction will be automatically rolled back by status code from context_async_sqlalchemy import db_session, rollback_db_session from sqlalchemy import insert from ..database import connection from ..models import ExampleTable async def handler_with_db_session_and_manual_rollback() -> None: \"\"\" An example of a handle that uses a rollback \"\"\" # it's convenient this way await _insert() await rollback_db_session(connection) # but it's possible this way too await _insert() session = await db_session(connection) await session.rollback() async def _insert() -> None: session = await db_session(connection) stmt = insert(ExampleTable).values( text=\"example_with_db_session_and_manual_close\" ) await session.execute(stmt)","title":"Rollback"},{"location":"getting_started/","text":"Getting started Configure the connection to the database for example for PostgreSQL database.py: from sqlalchemy.ext.asyncio import ( async_sessionmaker, AsyncEngine, AsyncSession, create_async_engine, ) from context_async_sqlalchemy import DBConnect def create_engine(host: str) -> AsyncEngine: \"\"\" database connection parameters. \"\"\" # In production code, you will probably take these parameters from env pg_user = \"krylosov-aa\" pg_password = \"\" pg_port = 6432 pg_db = \"test\" return create_async_engine( f\"postgresql+asyncpg://\" f\"{pg_user}:{pg_password}\" f\"@{host}:{pg_port}\" f\"/{pg_db}\", future=True, pool_pre_ping=True, ) def create_session_maker( engine: AsyncEngine, ) -> async_sessionmaker[AsyncSession]: \"\"\"session parameters\"\"\" return async_sessionmaker( engine, class_=AsyncSession, expire_on_commit=False ) connection = DBConnect( host=\"127.0.0.1\", engine_creator=create_engine, session_maker_creator=create_session_maker, ) Manage Database connection lifecycle Close the resources at the end of your application's life Example for FastAPI: from contextlib import asynccontextmanager from typing import Any, AsyncGenerator from fastapi import FastAPI from database import connection @asynccontextmanager async def lifespan(app: FastAPI) -> AsyncGenerator[None, Any]: \"\"\"Database connection lifecycle management\"\"\" yield await connection.close() # Close the engine if it was open Setup middleware Middleware takes on the most important and complex work of managing context and sessions. You can use ready-made middlewares: FastAPI from context_async_sqlalchemy.fastapi_utils import ( add_fastapi_http_db_session_middleware, ) app = FastAPI(...) add_fastapi_http_db_session_middleware(app) Starlette from context_async_sqlalchemy.starlette_utils import ( add_starlette_http_db_session_middleware, ) app = Starlette(...) add_starlette_http_db_session_middleware(app) Write own If there is no ready-made solution for you, don't worry! You can see how it works and write your own. Use it from context_async_sqlalchemy import db_session from sqlalchemy import insert from database import connection # your configured connection to the database from models import ExampleTable # just some model for example async def some_func() -> None: # Created a session (no connection to the database yet) session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) # The second request will use the same connection and the same transaction await session.execute(stmt) # The commit and closing of the session will occur automatically Examples The repository includes an example integration with FastAPI, which describes numerous workflows. FastAPI example It also includes two types of test setups you can use in your projects. All library tests are in the examples, as we want to test not in the abstract but in the context of a real asynchronous web application. FastAPI tests example","title":"Getting started"},{"location":"getting_started/#getting-started","text":"","title":"Getting started"},{"location":"getting_started/#configure-the-connection-to-the-database","text":"for example for PostgreSQL database.py: from sqlalchemy.ext.asyncio import ( async_sessionmaker, AsyncEngine, AsyncSession, create_async_engine, ) from context_async_sqlalchemy import DBConnect def create_engine(host: str) -> AsyncEngine: \"\"\" database connection parameters. \"\"\" # In production code, you will probably take these parameters from env pg_user = \"krylosov-aa\" pg_password = \"\" pg_port = 6432 pg_db = \"test\" return create_async_engine( f\"postgresql+asyncpg://\" f\"{pg_user}:{pg_password}\" f\"@{host}:{pg_port}\" f\"/{pg_db}\", future=True, pool_pre_ping=True, ) def create_session_maker( engine: AsyncEngine, ) -> async_sessionmaker[AsyncSession]: \"\"\"session parameters\"\"\" return async_sessionmaker( engine, class_=AsyncSession, expire_on_commit=False ) connection = DBConnect( host=\"127.0.0.1\", engine_creator=create_engine, session_maker_creator=create_session_maker, )","title":"Configure the connection to the database"},{"location":"getting_started/#manage-database-connection-lifecycle","text":"Close the resources at the end of your application's life Example for FastAPI: from contextlib import asynccontextmanager from typing import Any, AsyncGenerator from fastapi import FastAPI from database import connection @asynccontextmanager async def lifespan(app: FastAPI) -> AsyncGenerator[None, Any]: \"\"\"Database connection lifecycle management\"\"\" yield await connection.close() # Close the engine if it was open","title":"Manage Database connection lifecycle"},{"location":"getting_started/#setup-middleware","text":"Middleware takes on the most important and complex work of managing context and sessions. You can use ready-made middlewares:","title":"Setup middleware"},{"location":"getting_started/#fastapi","text":"from context_async_sqlalchemy.fastapi_utils import ( add_fastapi_http_db_session_middleware, ) app = FastAPI(...) add_fastapi_http_db_session_middleware(app)","title":"FastAPI"},{"location":"getting_started/#starlette","text":"from context_async_sqlalchemy.starlette_utils import ( add_starlette_http_db_session_middleware, ) app = Starlette(...) add_starlette_http_db_session_middleware(app)","title":"Starlette"},{"location":"getting_started/#write-own","text":"If there is no ready-made solution for you, don't worry! You can see how it works and write your own.","title":"Write own"},{"location":"getting_started/#use-it","text":"from context_async_sqlalchemy import db_session from sqlalchemy import insert from database import connection # your configured connection to the database from models import ExampleTable # just some model for example async def some_func() -> None: # Created a session (no connection to the database yet) session = await db_session(connection) stmt = insert(ExampleTable).values(text=\"example_with_db_session\") # On the first request, a connection and transaction were opened await session.execute(stmt) # If you call db_session again, it will return the same session # even in child coroutines. session = await db_session(connection) # The second request will use the same connection and the same transaction await session.execute(stmt) # The commit and closing of the session will occur automatically","title":"Use it"},{"location":"getting_started/#examples","text":"The repository includes an example integration with FastAPI, which describes numerous workflows. FastAPI example It also includes two types of test setups you can use in your projects. All library tests are in the examples, as we want to test not in the abstract but in the context of a real asynchronous web application. FastAPI tests example","title":"Examples"},{"location":"how_middleware_works/","text":"How middleware works The biggest part of the work and magic happens in middleware. The library strives to provide ready-made solutions so that you don't have to worry. But they are not always there. Therefore, we will tell you how starlette middleware works, using the example of which you can write your own. from starlette.middleware.base import ( # type: ignore[attr-defined] Request, Response, RequestResponseEndpoint, BaseHTTPMiddleware, ) from context_async_sqlalchemy import ( init_db_session_ctx, is_context_initiated, reset_db_session_ctx, auto_commit_by_status_code, rollback_all_sessions, ) async def starlette_http_db_session_middleware( request: Request, call_next: RequestResponseEndpoint ) -> Response: \"\"\" Database session lifecycle management. The session itself is created on demand in db_session(). Transaction auto-commit is implemented if there is no exception and the response status is < 400. Otherwise, a rollback is performed. But you can commit or rollback manually in the handler. \"\"\" # Tests have different session management rules # so if the context variable is already set, we do nothing if is_context_initiated(): return await call_next(request) # We set the context here, meaning all child coroutines will receive the # same context. And even if a child coroutine requests the # session first, the container itself is shared, and this coroutine will # add the session to container = shared context. token = init_db_session_ctx() try: response = await call_next(request) # using the status code, we decide to commit or rollback all sessions await auto_commit_by_status_code(response.status_code) return response except Exception: # If an exception occurs, we roll all sessions back await rollback_all_sessions() raise finally: # Close all sessions and clear the context await reset_db_session_ctx(token)","title":"How middleware works"},{"location":"how_middleware_works/#how-middleware-works","text":"The biggest part of the work and magic happens in middleware. The library strives to provide ready-made solutions so that you don't have to worry. But they are not always there. Therefore, we will tell you how starlette middleware works, using the example of which you can write your own. from starlette.middleware.base import ( # type: ignore[attr-defined] Request, Response, RequestResponseEndpoint, BaseHTTPMiddleware, ) from context_async_sqlalchemy import ( init_db_session_ctx, is_context_initiated, reset_db_session_ctx, auto_commit_by_status_code, rollback_all_sessions, ) async def starlette_http_db_session_middleware( request: Request, call_next: RequestResponseEndpoint ) -> Response: \"\"\" Database session lifecycle management. The session itself is created on demand in db_session(). Transaction auto-commit is implemented if there is no exception and the response status is < 400. Otherwise, a rollback is performed. But you can commit or rollback manually in the handler. \"\"\" # Tests have different session management rules # so if the context variable is already set, we do nothing if is_context_initiated(): return await call_next(request) # We set the context here, meaning all child coroutines will receive the # same context. And even if a child coroutine requests the # session first, the container itself is shared, and this coroutine will # add the session to container = shared context. token = init_db_session_ctx() try: response = await call_next(request) # using the status code, we decide to commit or rollback all sessions await auto_commit_by_status_code(response.status_code) return response except Exception: # If an exception occurs, we roll all sessions back await rollback_all_sessions() raise finally: # Close all sessions and clear the context await reset_db_session_ctx(token)","title":"How middleware works"},{"location":"master_replica/","text":"Master/Replica or several databases at the same time This is why db_session and other functions accept DBConnect as input. This way, you can work with multiple hosts simultaneously, for example, with the master and the replica. DBConnect also accepts factories instead of ready-made objects, so that you can easily change the host at the right time. For example, libpq can detect the master and replica to create an engine. However, it only does this once during creation. before_create_session_handler helps change the host in the runtime if the master or replica changes. You need a third-party functionality that helps determine the master or replica. I hope I can give you a ready solution soon too . The engine will not be created immediately when DBConnect is initialized. This will only happen on the first request. The library is lazy in many places. from context_async_sqlalchemy import DBConnect from master_replica_helper import get_master, get_replica async def renew_master_connect(connect: DBConnect) -> None: \"\"\"Updates the host if the master has changed\"\"\" master_host = await get_master() if master_host != connect.host: await connect.change_host(master_host) master = DBConnect( ..., before_create_session_handler=renew_master_connect, ) async def renew_replica_connect(connect: DBConnect) -> None: \"\"\"Updates the host if the replica has changed\"\"\" replica_host = await get_replica() if replica_host != connect.host: await connect.change_host(replica_host) replica = DBConnect( ..., before_create_session_handler=renew_replica_connect, )","title":"Master/Replica or several databases at the same time"},{"location":"master_replica/#masterreplica-or-several-databases-at-the-same-time","text":"This is why db_session and other functions accept DBConnect as input. This way, you can work with multiple hosts simultaneously, for example, with the master and the replica. DBConnect also accepts factories instead of ready-made objects, so that you can easily change the host at the right time. For example, libpq can detect the master and replica to create an engine. However, it only does this once during creation. before_create_session_handler helps change the host in the runtime if the master or replica changes. You need a third-party functionality that helps determine the master or replica. I hope I can give you a ready solution soon too . The engine will not be created immediately when DBConnect is initialized. This will only happen on the first request. The library is lazy in many places. from context_async_sqlalchemy import DBConnect from master_replica_helper import get_master, get_replica async def renew_master_connect(connect: DBConnect) -> None: \"\"\"Updates the host if the master has changed\"\"\" master_host = await get_master() if master_host != connect.host: await connect.change_host(master_host) master = DBConnect( ..., before_create_session_handler=renew_master_connect, ) async def renew_replica_connect(connect: DBConnect) -> None: \"\"\"Updates the host if the replica has changed\"\"\" replica_host = await get_replica() if replica_host != connect.host: await connect.change_host(replica_host) replica = DBConnect( ..., before_create_session_handler=renew_replica_connect, )","title":"Master/Replica or several databases at the same time"},{"location":"problem/","text":"The problem that the library solves Sqlalchemy has an engine that is responsible for the connection pool. The engine must be alive all the time the application is running in order to quickly issue ready connections to the application when it needs it. We use sessions in the application. The session receives one connection from the pool. The session should live a short time, at most for the processing time of one request, and often even less. Let's see what existing solutions are available to manage engine and session: Manual solution This is how the code is duplicated and that two connections and two transactions are used. And often in this case, one connection and one transaction were needed: @app.post(\"/users/\") async def create_user(name): await insert_user(name) await insert_user_profile(name) async def insert_user(name): async with get_async_session() as session: async with session.begin(): await session.execute(stmt) async def insert_user_profile(name): async with get_async_session() as session: async with session.begin(): await session.execute(stmt) You can move the duplicate code to a higher level, and then you get one connection and a transaction: @app.post(\"/users/\") async def create_user(name:): async with get_async_session() as session: async with session.begin(): await insert_user(name, session) await insert_user_profile(name, session) async def insert_user(name, session): await session.execute(stmt) async def insert_user_profile(name, session): await session.execute(stmt) But if you look at it globally, the code duplication doesn't go away. You need to do this in every handler: @app.post(\"/dogs/\") async def create_dog(name): async with get_async_session() as session: async with session.begin(): ... @app.post(\"/cats\") async def create_cat(name): async with get_async_session() as session: async with session.begin(): ... You also have to set up everything yourself. No ready-made integration solutions are used. On the one hand, freedom, on the other hand, a lot of code. Dependency You can use dependency. For example, in fatsapi it looks like this: async def get_atomic_session(): async with session_maker() as session: async with session.begin(): yield session @app.post(\"/dogs/\") async def create_dog(name, session=Depends(get_atomic_session)): ... @app.post(\"/cats/\") async def create_cat(name, session=Depends(get_atomic_session)): ... There are 2 problems here: You cannot close the session and transaction prematurely, because the dependency is responsible for this The session will have to be rolled from the very top of the stack down to the point where it is really needed By the way, there is no ready-made solution for integration into the framework here. Write the dependency itself yourself Wrappers over sqlalachemy There are various wrappers that often have more convenient integration Litestar, for example, has the advantages and disadvantages of dependency: config = SQLAlchemyAsyncConfig( connection_string=URL ) sqlalchemy_plugin = SQLAlchemyInitPlugin(config) class UserRepository(SQLAlchemyAsyncRepository[User]): model_type = User @post(\"/users\") async def create_user(data: User, repo: UserRepository): await repo.add(data) # <- insert into User here is an example of ormar: class BaseMeta(ormar.ModelMeta): ... class User(ormar.Model): ... @app.post(\"/users/\") async def create_user(name): await User.objects.create(name=name) The main problem with wrappers is that it's new knowledge that the developer needs to know. This is a new syntax. If a developer knows sqlalchemy they don't necessarily know the wrapper. Wrappers are also often conveniently designed with simple CRUD scripts, but complex SQL queries are very difficult to write. Solution And the library solves all this: Very convenient integration with web frameworks Automatic engine, session and transaction lifecycle management You can close the session manually without waiting for automation Getting a session out of context only where it is needed","title":"What problems it solves"},{"location":"problem/#the-problem-that-the-library-solves","text":"Sqlalchemy has an engine that is responsible for the connection pool. The engine must be alive all the time the application is running in order to quickly issue ready connections to the application when it needs it. We use sessions in the application. The session receives one connection from the pool. The session should live a short time, at most for the processing time of one request, and often even less. Let's see what existing solutions are available to manage engine and session:","title":"The problem that the library solves"},{"location":"problem/#manual-solution","text":"This is how the code is duplicated and that two connections and two transactions are used. And often in this case, one connection and one transaction were needed: @app.post(\"/users/\") async def create_user(name): await insert_user(name) await insert_user_profile(name) async def insert_user(name): async with get_async_session() as session: async with session.begin(): await session.execute(stmt) async def insert_user_profile(name): async with get_async_session() as session: async with session.begin(): await session.execute(stmt) You can move the duplicate code to a higher level, and then you get one connection and a transaction: @app.post(\"/users/\") async def create_user(name:): async with get_async_session() as session: async with session.begin(): await insert_user(name, session) await insert_user_profile(name, session) async def insert_user(name, session): await session.execute(stmt) async def insert_user_profile(name, session): await session.execute(stmt) But if you look at it globally, the code duplication doesn't go away. You need to do this in every handler: @app.post(\"/dogs/\") async def create_dog(name): async with get_async_session() as session: async with session.begin(): ... @app.post(\"/cats\") async def create_cat(name): async with get_async_session() as session: async with session.begin(): ... You also have to set up everything yourself. No ready-made integration solutions are used. On the one hand, freedom, on the other hand, a lot of code.","title":"Manual solution"},{"location":"problem/#dependency","text":"You can use dependency. For example, in fatsapi it looks like this: async def get_atomic_session(): async with session_maker() as session: async with session.begin(): yield session @app.post(\"/dogs/\") async def create_dog(name, session=Depends(get_atomic_session)): ... @app.post(\"/cats/\") async def create_cat(name, session=Depends(get_atomic_session)): ... There are 2 problems here: You cannot close the session and transaction prematurely, because the dependency is responsible for this The session will have to be rolled from the very top of the stack down to the point where it is really needed By the way, there is no ready-made solution for integration into the framework here. Write the dependency itself yourself","title":"Dependency"},{"location":"problem/#wrappers-over-sqlalachemy","text":"There are various wrappers that often have more convenient integration Litestar, for example, has the advantages and disadvantages of dependency: config = SQLAlchemyAsyncConfig( connection_string=URL ) sqlalchemy_plugin = SQLAlchemyInitPlugin(config) class UserRepository(SQLAlchemyAsyncRepository[User]): model_type = User @post(\"/users\") async def create_user(data: User, repo: UserRepository): await repo.add(data) # <- insert into User here is an example of ormar: class BaseMeta(ormar.ModelMeta): ... class User(ormar.Model): ... @app.post(\"/users/\") async def create_user(name): await User.objects.create(name=name) The main problem with wrappers is that it's new knowledge that the developer needs to know. This is a new syntax. If a developer knows sqlalchemy they don't necessarily know the wrapper. Wrappers are also often conveniently designed with simple CRUD scripts, but complex SQL queries are very difficult to write.","title":"Wrappers over sqlalachemy"},{"location":"problem/#solution","text":"And the library solves all this: Very convenient integration with web frameworks Automatic engine, session and transaction lifecycle management You can close the session manually without waiting for automation Getting a session out of context only where it is needed","title":"Solution"},{"location":"testing/","text":"Testing For testing with a real database, there is one important problem that needs to be solved - data isolation between tests. There are basically two approaches: The test has its own session with which it can prepare data for the test and verify the result of the test execution at the end. The application has its own session. Data isolation is achieved by clearing data from all tables at the end of each test (as well as once before running all tests) The test and the application share the same session and the same transaction. Data isolation is achieved by rolling back the transaction at the end of the test. Personally, I really like the first option. Because this is an honest testing of the application. We check how it works correctly with sessions and transactions on our own. It is also very convenient to check the status of the database when the test is suspended. And sometimes there are such complex session management scenarios (for example, concurrent query execution) in which other types of testing are either impossible or very difficult. The only disadvantage of such tests is the speed of their execution. Due to the fact that we clear all the tables after each test, we spend a lot of time on this. This is where the second type of testing comes on the scene, which has the only advantage in the speed of execution due to the fact that it is very fast to roll back the transaction. I use both approaches simultaneously in my projects. Most of the tests where the usual and simple logic is tested, I use a common transaction for the test and for the application. And where there is complex logic or it is simply not possible to test like this, I use tests with different transactions. This allows you to achieve good speed and good test convenience. The library provides several utils that can be used in tests, for example in fixtures. It helps write tests that share a common transaction between the test and the application, so data isolation between tests is achieved through fast transaction rollback. You can see the capabilities in the examples: Here are tests with a common transaction between the application and the tests. And here's an example with different transactions. Create session with autorollback rollback_session creates a session that always rolls back automatically. from context_async_sqlalchemy.test_utils import rollback_session @pytest_asyncio.fixture async def db_session_test() -> AsyncGenerator[AsyncSession]: \"\"\"The session that is used inside the test\"\"\" async with rollback_session(connection) as session: yield session Override context set_test_context creates a new context put_savepoint_session_in_ctx puts into context a session that uses the same connection as db_session_test , but if you commit in this session, then the transaction will not be committed, but save point will be released from context_async_sqlalchemy.test_utils import ( put_savepoint_session_in_ctx, set_test_context, ) @pytest_asyncio.fixture(autouse=True) async def db_session_override( db_session_test: AsyncSession, ) -> AsyncGenerator[None]: \"\"\" The key thing about these tests is that we override the context in advance. The middleware has a special check that won't initialize the context if it already exists. \"\"\" async with set_test_context(): async with put_savepoint_session_in_ctx(connection, db_session_test): yield","title":"Testing"},{"location":"testing/#testing","text":"For testing with a real database, there is one important problem that needs to be solved - data isolation between tests. There are basically two approaches: The test has its own session with which it can prepare data for the test and verify the result of the test execution at the end. The application has its own session. Data isolation is achieved by clearing data from all tables at the end of each test (as well as once before running all tests) The test and the application share the same session and the same transaction. Data isolation is achieved by rolling back the transaction at the end of the test. Personally, I really like the first option. Because this is an honest testing of the application. We check how it works correctly with sessions and transactions on our own. It is also very convenient to check the status of the database when the test is suspended. And sometimes there are such complex session management scenarios (for example, concurrent query execution) in which other types of testing are either impossible or very difficult. The only disadvantage of such tests is the speed of their execution. Due to the fact that we clear all the tables after each test, we spend a lot of time on this. This is where the second type of testing comes on the scene, which has the only advantage in the speed of execution due to the fact that it is very fast to roll back the transaction. I use both approaches simultaneously in my projects. Most of the tests where the usual and simple logic is tested, I use a common transaction for the test and for the application. And where there is complex logic or it is simply not possible to test like this, I use tests with different transactions. This allows you to achieve good speed and good test convenience. The library provides several utils that can be used in tests, for example in fixtures. It helps write tests that share a common transaction between the test and the application, so data isolation between tests is achieved through fast transaction rollback. You can see the capabilities in the examples: Here are tests with a common transaction between the application and the tests. And here's an example with different transactions.","title":"Testing"},{"location":"testing/#create-session-with-autorollback","text":"rollback_session creates a session that always rolls back automatically. from context_async_sqlalchemy.test_utils import rollback_session @pytest_asyncio.fixture async def db_session_test() -> AsyncGenerator[AsyncSession]: \"\"\"The session that is used inside the test\"\"\" async with rollback_session(connection) as session: yield session","title":"Create session with autorollback"},{"location":"testing/#override-context","text":"set_test_context creates a new context put_savepoint_session_in_ctx puts into context a session that uses the same connection as db_session_test , but if you commit in this session, then the transaction will not be committed, but save point will be released from context_async_sqlalchemy.test_utils import ( put_savepoint_session_in_ctx, set_test_context, ) @pytest_asyncio.fixture(autouse=True) async def db_session_override( db_session_test: AsyncSession, ) -> AsyncGenerator[None]: \"\"\" The key thing about these tests is that we override the context in advance. The middleware has a special check that won't initialize the context if it already exists. \"\"\" async with set_test_context(): async with put_savepoint_session_in_ctx(connection, db_session_test): yield","title":"Override context"}]}